{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage='''Whether in a crowded library or a dark bedroom, few experiences feel as personal as reading a book. Books are about eye and page, about one human brain in conversation with another.\n",
    "\n",
    "Yet the business of books is never quite about these airy virtues. And like any big business, publishing must always center on the mass: What do the most people want? What will the most people buy? What do people respond to?\n",
    "\n",
    "Between these two, there is a strange relationship. Companies collect and analyze this data, but rarely do readers get to see it.\n",
    "\n",
    "New data from Amazon, released to The Atlantic, gives us a peek at what, specifically, readers connect with. These are the most popular highlights in some of the service’s most popular books.\n",
    "\n",
    "Amazon doesn’t release sales data for Kindles, so the question of what makes the list of most-popular highlights is somewhat interesting. It takes more than 4,000 highlights to make something the most popular passage in Pride and Prejudice, but only about 650 for something to be the most popular highlight in The Lion, the Witch, and the Wardrobe.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whether in a crowded library or a dark bedroom, few experiences feel as personal as reading a book.',\n",
       " 'Books are about eye and page, about one human brain in conversation with another.',\n",
       " 'Yet the business of books is never quite about these airy virtues.',\n",
       " 'And like any big business, publishing must always center on the mass: What do the most people want?',\n",
       " 'What will the most people buy?',\n",
       " 'What do people respond to?',\n",
       " 'Between these two, there is a strange relationship.',\n",
       " 'Companies collect and analyze this data, but rarely do readers get to see it.',\n",
       " 'New data from Amazon, released to The Atlantic, gives us a peek at what, specifically, readers connect with.',\n",
       " 'These are the most popular highlights in some of the service’s most popular books.',\n",
       " 'Amazon doesn’t release sales data for Kindles, so the question of what makes the list of most-popular highlights is somewhat interesting.',\n",
       " 'It takes more than 4,000 highlights to make something the most popular passage in Pride and Prejudice, but only about 650 for something to be the most popular highlight in The Lion, the Witch, and the Wardrobe.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentense=nltk.sent_tokenize(passage)\n",
    "sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentense)):\n",
    "    sentense[i]=sentense[i].lower()\n",
    "    sentense[i]=re.sub(r'\\W',' ',sentense[i])\n",
    "    sentense[i]=re.sub(r'\\s+',' ',sentense[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whether': 1,\n",
       " 'in': 5,\n",
       " 'a': 5,\n",
       " 'crowded': 1,\n",
       " 'library': 1,\n",
       " 'or': 1,\n",
       " 'dark': 1,\n",
       " 'bedroom': 1,\n",
       " 'few': 1,\n",
       " 'experiences': 1,\n",
       " 'feel': 1,\n",
       " 'as': 2,\n",
       " 'personal': 1,\n",
       " 'reading': 1,\n",
       " 'book': 1,\n",
       " 'books': 3,\n",
       " 'are': 2,\n",
       " 'about': 4,\n",
       " 'eye': 1,\n",
       " 'and': 5,\n",
       " 'page': 1,\n",
       " 'one': 1,\n",
       " 'human': 1,\n",
       " 'brain': 1,\n",
       " 'conversation': 1,\n",
       " 'with': 2,\n",
       " 'another': 1,\n",
       " 'yet': 1,\n",
       " 'the': 14,\n",
       " 'business': 2,\n",
       " 'of': 4,\n",
       " 'is': 3,\n",
       " 'never': 1,\n",
       " 'quite': 1,\n",
       " 'these': 3,\n",
       " 'airy': 1,\n",
       " 'virtues': 1,\n",
       " 'like': 1,\n",
       " 'any': 1,\n",
       " 'big': 1,\n",
       " 'publishing': 1,\n",
       " 'must': 1,\n",
       " 'always': 1,\n",
       " 'center': 1,\n",
       " 'on': 1,\n",
       " 'mass': 1,\n",
       " 'what': 5,\n",
       " 'do': 3,\n",
       " 'most': 7,\n",
       " 'people': 3,\n",
       " 'want': 1,\n",
       " 'will': 1,\n",
       " 'buy': 1,\n",
       " 'respond': 1,\n",
       " 'to': 5,\n",
       " 'between': 1,\n",
       " 'two': 1,\n",
       " 'there': 1,\n",
       " 'strange': 1,\n",
       " 'relationship': 1,\n",
       " 'companies': 1,\n",
       " 'collect': 1,\n",
       " 'analyze': 1,\n",
       " 'this': 1,\n",
       " 'data': 3,\n",
       " 'but': 2,\n",
       " 'rarely': 1,\n",
       " 'readers': 2,\n",
       " 'get': 1,\n",
       " 'see': 1,\n",
       " 'it': 2,\n",
       " 'new': 1,\n",
       " 'from': 1,\n",
       " 'amazon': 2,\n",
       " 'released': 1,\n",
       " 'atlantic': 1,\n",
       " 'gives': 1,\n",
       " 'us': 1,\n",
       " 'peek': 1,\n",
       " 'at': 1,\n",
       " 'specifically': 1,\n",
       " 'connect': 1,\n",
       " 'popular': 5,\n",
       " 'highlights': 3,\n",
       " 'some': 1,\n",
       " 'service': 1,\n",
       " 's': 1,\n",
       " 'doesn': 1,\n",
       " 't': 1,\n",
       " 'release': 1,\n",
       " 'sales': 1,\n",
       " 'for': 2,\n",
       " 'kindles': 1,\n",
       " 'so': 1,\n",
       " 'question': 1,\n",
       " 'makes': 1,\n",
       " 'list': 1,\n",
       " 'somewhat': 1,\n",
       " 'interesting': 1,\n",
       " 'takes': 1,\n",
       " 'more': 1,\n",
       " 'than': 1,\n",
       " '4': 1,\n",
       " '000': 1,\n",
       " 'make': 1,\n",
       " 'something': 2,\n",
       " 'passage': 1,\n",
       " 'pride': 1,\n",
       " 'prejudice': 1,\n",
       " 'only': 1,\n",
       " '650': 1,\n",
       " 'be': 1,\n",
       " 'highlight': 1,\n",
       " 'lion': 1,\n",
       " 'witch': 1,\n",
       " 'wardrobe': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count={}\n",
    "for words in sentense:\n",
    "    word1=nltk.word_tokenize(words)\n",
    "    for word in word1:\n",
    "        if word not in word2count:\n",
    "            word2count[word]=1\n",
    "        else:\n",
    "            word2count[word]+=1\n",
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_word=heapq.nlargest(10,word2count,key=word2count.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'most', 'in', 'a', 'and', 'what', 'to', 'popular', 'about', 'of']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in freq_word:\n",
    "    doc_count=0\n",
    "    for data in sentense:\n",
    "        if i in nltk.word_tokenize(data):\n",
    "            doc_count+=1\n",
    "    word_idfs[i]=np.log((len(sentense)/doc_count)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.9985288301111273,\n",
       " 'most': 1.2237754316221157,\n",
       " 'in': 1.3862943611198906,\n",
       " 'a': 1.6094379124341003,\n",
       " 'and': 1.3862943611198906,\n",
       " 'what': 1.2237754316221157,\n",
       " 'to': 1.3862943611198906,\n",
       " 'popular': 1.6094379124341003,\n",
       " 'about': 1.6094379124341003,\n",
       " 'of': 1.6094379124341003}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in freq_word:\n",
    "    doc_tf=[]\n",
    "    for data in sentense:\n",
    "        freq=0\n",
    "        for w in nltk.word_tokenize(data):\n",
    "            if(w==word):\n",
    "                freq+=1\n",
    "        tf_word=freq/len(nltk.word_tokenize(data))\n",
    "        doc_tf.append(tf_word)\n",
    "    tf_matrix[word]=doc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': [0.0,\n",
       "  0.0,\n",
       "  0.08333333333333333,\n",
       "  0.1111111111111111,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.13333333333333333,\n",
       "  0.08695652173913043,\n",
       "  0.13157894736842105],\n",
       " 'most': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.13333333333333333,\n",
       "  0.043478260869565216,\n",
       "  0.05263157894736842],\n",
       " 'in': [0.05555555555555555,\n",
       "  0.07142857142857142,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.0,\n",
       "  0.05263157894736842],\n",
       " 'a': [0.16666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.125,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'and': [0.0,\n",
       "  0.07142857142857142,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07142857142857142,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05263157894736842],\n",
       " 'what': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.16666666666666666,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05555555555555555,\n",
       "  0.0,\n",
       "  0.043478260869565216,\n",
       "  0.0],\n",
       " 'to': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.07142857142857142,\n",
       "  0.05555555555555555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05263157894736842],\n",
       " 'popular': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.13333333333333333,\n",
       "  0.043478260869565216,\n",
       "  0.05263157894736842],\n",
       " 'about': [0.0,\n",
       "  0.14285714285714285,\n",
       "  0.08333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.02631578947368421],\n",
       " 'of': [0.0,\n",
       "  0.0,\n",
       "  0.08333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06666666666666667,\n",
       "  0.08695652173913043,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_cal=[]\n",
    "for word in tf_matrix.keys():\n",
    "    tf_idf=[]\n",
    "    for value in tf_matrix[word]:\n",
    "        score=value*word_idfs[word]\n",
    "        tf_idf.append(score)\n",
    "    tf_idf_cal.append(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.08321073584259393,\n",
       "  0.11094764779012524,\n",
       "  0.16642147168518787,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05547382389506262,\n",
       "  0.1331371773481503,\n",
       "  0.08682859392270671,\n",
       "  0.13138537238304304],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06798752397900643,\n",
       "  0.20396257193701928,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16317005754961542,\n",
       "  0.053207627461831115,\n",
       "  0.06440923324326925],\n",
       " [0.07701635339554948,\n",
       "  0.09902102579427789,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09241962407465937,\n",
       "  0.0,\n",
       "  0.07296286111157319],\n",
       " [0.26823965207235,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20117973905426254,\n",
       "  0.0,\n",
       "  0.08941321735745002,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.09902102579427789,\n",
       "  0.0,\n",
       "  0.07701635339554948,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09902102579427789,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07296286111157319],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06798752397900643,\n",
       "  0.20396257193701928,\n",
       "  0.24475508632442314,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06798752397900643,\n",
       "  0.0,\n",
       "  0.053207627461831115,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2772588722239781,\n",
       "  0.0,\n",
       "  0.09902102579427789,\n",
       "  0.07701635339554948,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07296286111157319],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.21459172165788004,\n",
       "  0.06997556141017827,\n",
       "  0.08470725854916317],\n",
       " [0.0,\n",
       "  0.22991970177630003,\n",
       "  0.134119826036175,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.04235362927458158],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.134119826036175,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10729586082894002,\n",
       "  0.13995112282035654,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_cal=np.asarray(tf_idf_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.08321074, 0.11094765, 0.16642147,\n",
       "        0.        , 0.        , 0.        , 0.05547382, 0.13313718,\n",
       "        0.08682859, 0.13138537],\n",
       "       [0.        , 0.        , 0.        , 0.06798752, 0.20396257,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16317006,\n",
       "        0.05320763, 0.06440923],\n",
       "       [0.07701635, 0.09902103, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09241962,\n",
       "        0.        , 0.07296286],\n",
       "       [0.26823965, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20117974, 0.        , 0.08941322, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.09902103, 0.        , 0.07701635, 0.        ,\n",
       "        0.        , 0.        , 0.09902103, 0.        , 0.        ,\n",
       "        0.        , 0.07296286],\n",
       "       [0.        , 0.        , 0.        , 0.06798752, 0.20396257,\n",
       "        0.24475509, 0.        , 0.        , 0.06798752, 0.        ,\n",
       "        0.05320763, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.27725887, 0.        , 0.09902103, 0.07701635, 0.        ,\n",
       "        0.        , 0.07296286],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21459172,\n",
       "        0.06997556, 0.08470726],\n",
       "       [0.        , 0.2299197 , 0.13411983, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04235363],\n",
       "       [0.        , 0.        , 0.13411983, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10729586,\n",
       "        0.13995112, 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
